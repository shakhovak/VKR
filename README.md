# Репозиторий для кода в рамках дипломного проекта СОЗДАНИЕ SOTA МОДЕЛИ ДЛЯ АСПЕКТНОЙ ТОНАЛЬНОСТИ 

Данные репозиторий предназначен для хранения кода в рамках подготовки дипломного проекта. 

Аспектная тональность, являясь подзадачей анализа тональности, направлена на ее более гранулированное изучение и извлечение из текста аспектов – объектов оценки пользователей, слов-мнений, оценивающих объект, а таже классификацией самой оценки и ее категории. Одно из направлений исследования в аспектной тональности касается поиска алгоритмов обучения и архитектур моделей, которые позволят создать универсальную и легко масштабируемую модель для извлечения всех аспектных сущностей. Основной целью данного исследования является создание такой модели для извлечения из корпуса текстов аспекта и его тональности (задача E2E-ABSA).

![image](https://github.com/shakhovak/VKR/assets/89096305/65c8ae9d-b381-407d-b822-d95d3c44b9ed)

## Первый этап исследований
Основной задачей в рамках 1-го этапа экспериментов является тестирование типовых подходов в парадигмах классификации токенов и классификации последовательности на выбранном датасете для задач анализа аспектной тональности, выявление и подтверждение их ограничений с целью понимания, что seq2seq является максимально универсальной парадигмой для создания масштабируемой модели для решения задач ABSA.

**1. ABSA как классификация токенов**
Код для исследования в виде ноубука в папке ```TokenClassif_approach ``` [ссылка](https://github.com/shakhovak/VKR/tree/master/TokenClassif_approach). Данный подход не был выбран в качестве основного для проверки гипотезы.

**2. ABSA как классификация последовательности**
Код для исследования в виде ноубука в папке ```SeqClassif_approach ``` [ссылка](https://github.com/shakhovak/VKR/tree/master/SeqClassif_approach). Данный подход не был выбран в качестве основного для проверки гипотезы.

**3. ABSA как Seq2Seq**
Код для исследования в виде ноубука в папке ```Seq2Seq_approach``` [ссылка](https://github.com/shakhovak/VKR/tree/master/Seq2Seq_approach). Данный подход был в качестве основного для проверки гипотезы.

## Второй этап исследований
В качестве основной парадигмы для решения задачи E2E-ABSA был выбран seq2seq подход на основе генеративных моделей, обучающихся с помощью инструкций. В рамках этой парадигмы тестируется гипотеза, что совместное использование инструкций в виде вопросов и просьб на естественном языке с упоминанием извлекаемых сущностей вместе с совместным обучением на разные задачи (multi-task) позволит улучшить метрики качества модели до уровня SOTA. В рамках данного проекта сравниваются результативность моделей при использовании single-task - одной инструкции с запросом пары сущностей (<аспект: тональность>) и одновременном обучении этих же моделей на 3 задачи сразу (multi-task).

Скрипты для исследования в папке ```ABSA_2nd_stage```. Структура папки:
```
│   requirements.txt – основные библиотеки для установки
│   utils.py - вспомогательные функции в т.ч. для предобработки данных
│   prompts_absa.json – инструкции для single-task
│   prompts_joint.json – инструкции для multi-task
│  
├───scripts – папка со скриптами для запуска заданий
│                main.py, 
│                main_fmt.py
│                main_joint.py
│                main_fmt_joint.py
│                main_lora.py
│                main_fmt_lora.py
│                main_llama.py
│                main_fmt_llama.py
│                main_mistral.py
│                main_fmt_mistral.py
│  
├───configs – папка с конфигами для запуска заданий
├───Llama_metric_rework – перерасчет метрики для моделей c Llama
```
Для автоматизации запуска экспериментов используется облачная среда Yandex DataSphere. Для запуска заданий необходимо создать локальное окружение и файл requirements.txt со всеми установленными библиотеками. В окружение устанавливается библиотека datasphere, которая управляет запусками и взаимодействием с ресурсами в облаке. Для каждого варианта модели создается 2 файла: скрипт с исполнением кода обучения и файл конфигурации, также включающий командную строку для передачи аргументов в скрипте. 

Для запуска скрипта необходимо сперва создать проект в облаке, где будут запускаться скрипты. В проект добавить нужных пользователей и токены для доступа на порталы hugging face и wandb. Также для локального компьютера нужно создать ключи для доступа к облачным сервисам. Запускается каждый скрипт из командой строки локального компьютера с указанием идентификационного номера проекта, где будет развернуто временное окружение, и названия config.yaml файла. Пример команды выглядит следующим образом: ```datasphere project job execute -p <ID проекта> -c config.yaml```. 

**Описание экспериментов:**
![image](https://github.com/shakhovak/VKR/assets/89096305/751fe06f-4570-405d-b855-f929b1e225ba)


### Результаты экспериментов

![image](https://github.com/shakhovak/VKR/assets/89096305/3af55683-749d-41fb-bc15-a4bcfe62beb9)

- В 11 из 13 экспериментов multi-task лучше single-task в среднем на 1,8%
- REST лучше UnifiedABSA на 7,59%, InstructABSA на 5,09% и до-обученный GPT 3.5 на 2,10%
- LAPTOPS лучше UnifiedABSA на 9,72%, InstructABSA на 6,78% и до-обученный GPT 3.5 на 3,45%

Подводя итог, можно сказать, что поставленные задачи исследования выполнены полностью, подтверждена сформулированная гипотеза и  достигнута основная цель исследования.



