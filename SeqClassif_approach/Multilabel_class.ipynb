{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача нахождения категории аспекта и его тональности как многомерная классфикация предложения\n",
    "\n",
    "В этом ноутбуке я рассмотрю нахождение категории авспекта/аспектов и их тональности через задачу Seq2Seq классификации. Так у одного предложения может быть несколько категорий, но лейблы будет соединением категории и тональности, таким образом один конкретный лейбл может быть только один раз в векторе возможных лейблов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4a231e",
   "metadata": {
    "cellId": "p75dvo71vkay6rzwkr5r1"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bf9ba4",
   "metadata": {
    "cellId": "0f1wnlmcr39it5zuggtugdn"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc5456bd1934f64922d6948cd668d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/10.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d282437224c4cdca8937a067329de5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a907fa92b9b4526a5f0b2c936bb5aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/35.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0ed034adf54fd1961e46a980b759b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9bf066d9b742fbab2e2ce2748ab742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/359k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcd6f69564744bd9e5c35ff6952a0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e524a8dfffd4918a27a475e0343f202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating trial split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc533f3a3a054104b3a0564549bff516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090d07e93c0240c0a2c7f42151d7766e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    trial: Dataset({\n",
       "        features: ['sentenceId', 'text', 'aspectTerms', 'aspectCategories'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['sentenceId', 'text', 'aspectTerms', 'aspectCategories'],\n",
       "        num_rows: 3041\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentenceId', 'text', 'aspectTerms', 'aspectCategories'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.1\n",
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"alexcadillon/SemEval2014Task4\", 'restaurants')\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae57d8b",
   "metadata": {
    "cellId": "zqdl6aezvhbd0ekrlltry5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['service', 'food', 'anecdotes/miscellaneous', 'ambience', 'price']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.1\n",
    "categories = []\n",
    "for i in raw_datasets['train']['aspectCategories']:\n",
    "    if i[0]['category'] not in categories:\n",
    "        categories.append(i[0]['category'])\n",
    "categories    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d94d258c",
   "metadata": {
    "cellId": "r2fktzwxbpld2c9uzkb7kw"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "labels = ['service_positive', 'service_negative', 'service_neutral', 'service_conflict',\n",
    "          'food_positive', 'food_negative', 'food_neutral', 'food_conflict',\n",
    "          'anecdotes/miscellaneous_positive', 'anecdotes/miscellaneous_negative', 'anecdotes/miscellaneous_neutral', 'anecdotes/miscellaneous_conflict',\n",
    "          'ambience_positive', 'ambience_negative', 'ambience_neutral', 'ambience_conflict',\n",
    "          'price_positive','price_negative' , 'price_neutral', 'price_conflict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c60aefb5",
   "metadata": {
    "cellId": "hi7gd80yjipsz8tiz8vdib"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'service_positive': 0,\n",
       " 'service_negative': 1,\n",
       " 'service_neutral': 2,\n",
       " 'service_conflict': 3,\n",
       " 'food_positive': 4,\n",
       " 'food_negative': 5,\n",
       " 'food_neutral': 6,\n",
       " 'food_conflict': 7,\n",
       " 'anecdotes/miscellaneous_positive': 8,\n",
       " 'anecdotes/miscellaneous_negative': 9,\n",
       " 'anecdotes/miscellaneous_neutral': 10,\n",
       " 'anecdotes/miscellaneous_conflict': 11,\n",
       " 'ambience_positive': 12,\n",
       " 'ambience_negative': 13,\n",
       " 'ambience_neutral': 14,\n",
       " 'ambience_conflict': 15,\n",
       " 'price_positive': 16,\n",
       " 'price_negative': 17,\n",
       " 'price_neutral': 18,\n",
       " 'price_conflict': 19}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.1\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9074056f",
   "metadata": {
    "cellId": "xg2sibu6bu9y85znlo0ja"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentenceId': '2846',\n",
       " 'text': \"Not only was the food outstanding, but the little 'perks' were great.\",\n",
       " 'aspectTerms': [{'term': 'food',\n",
       "   'polarity': 'positive',\n",
       "   'from': '17',\n",
       "   'to': '21'},\n",
       "  {'term': 'perks', 'polarity': 'positive', 'from': '51', 'to': '56'}],\n",
       " 'aspectCategories': [{'category': 'food', 'polarity': 'positive'},\n",
       "  {'category': 'service', 'polarity': 'positive'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.1\n",
    "sample = raw_datasets['train'][5]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aff7baed",
   "metadata": {
    "cellId": "09imqijt7uk62hrmzrp0rhj"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "def combo_label(example):   \n",
    "    labels_combo = []\n",
    "    for item in example['aspectCategories']:\n",
    "        labels_combo.append(f\"{item['category']}_{item['polarity']}\")\n",
    "    example['labels_combo'] = labels_combo\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2999666",
   "metadata": {
    "cellId": "qjbc59ahlnt7ty640s62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function combo_label at 0x7f381a027b50> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded2223eedc74b0a823a4ebabbcef0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e274a0d638f14c5a99f86f798081aff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0057e247f8e64a86ab201c88bfc84da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    trial: Dataset({\n",
       "        features: ['sentenceId', 'text', 'aspectTerms', 'aspectCategories', 'labels_combo'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['sentenceId', 'text', 'aspectTerms', 'aspectCategories', 'labels_combo'],\n",
       "        num_rows: 3041\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentenceId', 'text', 'aspectTerms', 'aspectCategories', 'labels_combo'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.1\n",
    "dataset = raw_datasets.map(combo_label)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c42bcdc",
   "metadata": {
    "cellId": "ccblpgjfnxtjinvx1lnzs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentenceId': '3121',\n",
       " 'text': 'But the staff was so horrible to us.',\n",
       " 'aspectTerms': [{'term': 'staff',\n",
       "   'polarity': 'negative',\n",
       "   'from': '8',\n",
       "   'to': '13'}],\n",
       " 'aspectCategories': [{'category': 'service', 'polarity': 'negative'}],\n",
       " 'labels_combo': ['service_negative']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.1\n",
    "sample = dataset['train'][0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3f1537",
   "metadata": {
    "cellId": "071ovfcx19pty5ekcm7q5u"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d81c1365ef34326a24dd99b7a86672b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/710 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0958f52a2f0a4087a4d78e1667aa65fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65219bb1fbc408f9bf553cb95f49e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g2.1\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"albert-xxlarge-v2\")\n",
    "label_counts = len(labels)\n",
    "\n",
    "def preprocess_data(example):\n",
    "  # take a batch of texts\n",
    "  text = example[\"text\"]\n",
    "  # encode them\n",
    "  encoding = tokenizer(text, add_special_tokens=True)\n",
    "  # add labels\n",
    "  label_ids = [0 for i in range(label_counts)]\n",
    "  for item in example['labels_combo']:\n",
    "            new = [1.0 if l == labels.index(item) else 0.0 for l in range(label_counts)]\n",
    "            label_ids = [x+y for x,y in zip(label_ids, new)]\n",
    "            new = [0 for i in range(label_counts)]\n",
    "\n",
    "  encoding[\"labels\"] = label_ids\n",
    "\n",
    "  return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1fa7241",
   "metadata": {
    "cellId": "ujktinhdrtuxpsc6go8x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 47, 14, 1138, 23, 86, 9244, 20, 182, 9, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.1\n",
    "preprocess_data(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "636510a7",
   "metadata": {
    "cellId": "cqiihq3udhgqnslemgcxmo"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970d8a5cd99b4a9ebfbb5e7804017689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3364e3d76914a578c97c08a59364bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9aaae57a2447a6b4532ab43cf54d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    trial: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3041\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.1\n",
    "tokenized_dataset = dataset.map(preprocess_data, remove_columns=dataset['train'].column_names)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65741e33",
   "metadata": {
    "cellId": "p894aa57r8tn59nekvs1r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentenceId': '3359',\n",
       " 'text': 'The pizza is the best if you like thin crusted pizza.',\n",
       " 'aspectTerms': [{'term': 'pizza',\n",
       "   'polarity': 'positive',\n",
       "   'from': '4',\n",
       "   'to': '9'},\n",
       "  {'term': 'thin crusted pizza',\n",
       "   'polarity': 'neutral',\n",
       "   'from': '34',\n",
       "   'to': '52'}],\n",
       " 'aspectCategories': [{'category': 'food', 'polarity': 'positive'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.1\n",
    "raw_datasets['train'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e9a7537",
   "metadata": {
    "cellId": "afrfhusritaxnsleoanwq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "example = tokenized_dataset['train'][15]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "764fdb5e",
   "metadata": {
    "cellId": "obe6lg0yram97gbjc927"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 19:15:01.511496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] the pizza is the best if you like thin crusted pizza.[SEP]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.1\n",
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf9ee8cc",
   "metadata": {
    "cellId": "uxddtuw1s1a61f7wefqogv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.1\n",
    "example['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb7a197f",
   "metadata": {
    "cellId": "ebvv77qadxp5zd4305ddkv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food_positive']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.1\n",
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6869432",
   "metadata": {
    "cellId": "zv4rmf28tvspcin4nzrpxo"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "tokenized_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48529f67",
   "metadata": {
    "cellId": "kt8ncs4yol9p2lbqk1l8v"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d5a7b7fa414a7880f57e5978446dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/893M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-xxlarge-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"albert-xxlarge-v2\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f85c82e",
   "metadata": {
    "cellId": "8dmb2jtokgplvioimt2pl8"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6172cb0",
   "metadata": {
    "cellId": "8f1ba17ikbi2apmftrit2i"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08abff75",
   "metadata": {
    "cellId": "wu1mzce5yulp0xjdh10r7m"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"bert-finetuned-sem_eval-english\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e133b380",
   "metadata": {
    "cellId": "3ay208kvvm7ehg25wg3miw"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'macro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be1bf2dd",
   "metadata": {
    "cellId": "495b59fdry8xjfmgj0jeke"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a AlbertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 10:12, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.103340</td>\n",
       "      <td>0.301529</td>\n",
       "      <td>0.639495</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>0.070195</td>\n",
       "      <td>0.451156</td>\n",
       "      <td>0.708728</td>\n",
       "      <td>0.688750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.068412</td>\n",
       "      <td>0.535523</td>\n",
       "      <td>0.748901</td>\n",
       "      <td>0.708750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.558758</td>\n",
       "      <td>0.760101</td>\n",
       "      <td>0.738750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.065141</td>\n",
       "      <td>0.559589</td>\n",
       "      <td>0.760702</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.06798371542782922, metrics={'train_runtime': 614.0828, 'train_samples_per_second': 24.761, 'train_steps_per_second': 3.102, 'total_flos': 702077429356296.0, 'train_loss': 0.06798371542782922, 'epoch': 5.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.1\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator = data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Финальные выводы\n",
    "\n",
    "Результаты получились довольно посредственные, так как я ничего не делала с дисбалансом классов, особо низкая метрика F1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "c7f96300-cba7-4b39-a5ee-8459d39cdd53",
  "notebookPath": "Multilabel_class.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
